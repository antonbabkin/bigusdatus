{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "> Analysis examples, using different formats and processors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pandas\n",
    "\n",
    "In-memory processing of data internally stored in NumPy arrays.\n",
    "\n",
    "[Scaling suggestions](https://pandas.pydata.org/pandas-docs/stable/user_guide/scale.html) in official pandas documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dask\n",
    "\n",
    "[Website](https://dask.org/)\n",
    "[Docs](https://docs.dask.org/en/latest/)\n",
    "[Tutorial](https://tutorial.dask.org/)\n",
    "[Examples](https://examples.dask.org/index.html)\n",
    "\n",
    "## Distributed scheduler\n",
    "\n",
    "[Docs](https://distributed.dask.org/en/latest/)\n",
    "\n",
    "Dask default port for dashboard diagnostics is 8787, which is also default port for RStudio server (rserver).\n",
    "A solution is to start client (or cluster) with parameter `dashboard_address=\"localhost:8899\"`.\n",
    "Whether setting default port in config file is possible is [unknown](https://stackoverflow.com/questions/60535300/dask-distributed-configuration-file-for-dashboard-address)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from ig_format import storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeated cross-section analysis\n",
    "\n",
    "Every year can be processed one at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# pandas\n",
    "df = storage.read_csv(2000, full=True)\n",
    "res = dict()\n",
    "for c in ['employees']:\n",
    "#     res[c] = (df[c].sum(), df[c].mean(), df[c].std())\n",
    "    res[c] = (df[c].sum())\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dask\n",
    "import dask\n",
    "import dask.config\n",
    "import dask.distributed\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = dask.distributed.Client(dashboard_address='localhost:8899')\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "year = 2000\n",
    "dt = storage.dtypes_from_schema(f'./data/csv/{year}_schema.json', False)\n",
    "df = dd.read_csv(f'./data/csv/{year}.csv', dtype=dt)\n",
    "res = dict()\n",
    "c = 'employees'\n",
    "res[c] = (df['employees'].sum().compute())\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = 'count count_na count_notna count_unique min max sum mean std p1 p25 p50 p75 p99'.split()\n",
    "defaults = [pd.np.nan] * len(fields)\n",
    "Stats = namedtuple('Stats', fields, defaults=defaults)\n",
    "\n",
    "def comp_stats(s):\n",
    "    \"\"\"Return dictionary of stats computed from a Series.\"\"\"\n",
    "    count = len(s)\n",
    "    na = s.isna().sum()\n",
    "    if pd.api.types.is_numeric_dtype(s):\n",
    "        q = s.quantile([0, 0.01, 0.25, 0.5, 0.75, 0.99, 1])\n",
    "        num_stats = dict(min=q[0], max=q[1], sum=s.sum(), mean=s.mean(), std=s.std(),\n",
    "                         p1=q[0.01], p25=q[0.25], p50=q[0.5], p75=q[0.75], p99=q[0.99])\n",
    "    else:\n",
    "        num_stats = dict()\n",
    "    return Stats(count=count, count_na=na, count_notna=count - na, count_unique=s.nunique(), **num_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_by_year = {}\n",
    "stat_cols = ['sales', 'employees', 'state', 'naics2']\n",
    "for y in data_years:\n",
    "    dt = dtypes_from_schema(schema_path)\n",
    "    df = pd.read_csv(f'{data_dir}/{y}.csv', dtype=dt)\n",
    "    df['naics2'] = df['naics'].str[:2]\n",
    "    s = [comp_stats(df[c]) for c in stat_cols]\n",
    "    s = pd.DataFrame(s, index=stat_cols)\n",
    "    stats_by_year[y] = s\n",
    "stats_by_year = pd.concat(stats_by_year).reorder_levels([1, 0]).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_by_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg = df.groupby('naics2')\n",
    "dfg['sales'].apply(lambda c: pd.Series(comp_stats(c))).to_frame().unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic analysis\n",
    "\n",
    "Growth rates that take two years simultaneously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full panel analysis\n",
    "\n",
    "Use all years to run a regression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
