{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import os\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raw data\n",
    "\n",
    "> Original raw data comes in CSV format, every year of data in a separate file. In this module, we construct schema that adheres to [Frictionless Data specificaitons](https://frictionlessdata.io/specs/), validate each table and erase problematic entries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original data\n",
    "\n",
    "Create symlinks from data location to \"./in\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate against schema\n",
    "\n",
    "That code is in a separate repo, and is possibly outdated. For now download validated and cleaned files from GCS.\n",
    "\n",
    "```\n",
    "mkdir -p out/valid\n",
    "gsutil -m cp -r gs://info-group-corr/* out/valid/\n",
    "```\n",
    "\n",
    "The last 2 years (2016 and 2017) are missing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To report number of lines, is it faster to iterate through file in Python or use system `wc` utility?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def wc_py(fpath):\n",
    "    \"Return number of lines in a text file, using Python I/O.\"\n",
    "    with open(fpath) as f:\n",
    "        line_count = 0\n",
    "        for _ in f:\n",
    "            line_count += 1\n",
    "    return line_count\n",
    "\n",
    "def wc_sys(fpath):\n",
    "    \"Return number of lines in a text file, using sytem 'wc' utility.\"\n",
    "    p = subprocess.run(['wc', '-l', fpath], capture_output=True, text=True)\n",
    "    return int(p.stdout.split()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "fpath = './README.md'\n",
    "assert wc_py(fpath) == wc_sys(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9 s, sys: 1.47 s, total: 10.5 s\n",
      "Wall time: 10.4 s\n",
      "CPU times: user 6.76 ms, sys: 0 ns, total: 6.76 ms\n",
      "Wall time: 1.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11169277"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# notest\n",
    "fpath = './out/valid/2000.csv'\n",
    "%time wc_py(fpath)\n",
    "%time wc_sys(fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it is faster to use sytem `wc` utility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from hurry.filesize import size\n",
    "\n",
    "def lsdir(fdir):\n",
    "    \"\"\"Return list of strings like \"file_name file_size number_of_lines\" for all files in :fdir:.\"\"\"\n",
    "    fpaths = []\n",
    "    for fname in os.listdir(fdir):\n",
    "        fpath = os.path.join(fdir, fname)\n",
    "        if not os.path.isfile(fpath):\n",
    "            continue\n",
    "        fpaths.append(fpath)\n",
    "    \n",
    "    info = ['Name\\tLines\\tSize']\n",
    "    for fpath in sorted(fpaths):\n",
    "        wc = wc_sys(fpath)\n",
    "        sz = size(os.path.getsize(fpath))\n",
    "        info.append(f'{fpath}\\t{wc}\\t{sz}')\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name\tLines\tSize\n",
      "./out/valid/1997.csv\t11263922\t2G\n",
      "./out/valid/1998.csv\t10774212\t2G\n",
      "./out/valid/1999.csv\t11020067\t3G\n",
      "./out/valid/2000.csv\t11169277\t3G\n",
      "./out/valid/2001.csv\t12549385\t3G\n",
      "./out/valid/2002.csv\t12848950\t3G\n",
      "./out/valid/2003.csv\t12743181\t3G\n",
      "./out/valid/2004.csv\t12616725\t3G\n",
      "./out/valid/2005.csv\t13196450\t3G\n",
      "./out/valid/2006.csv\t13350451\t3G\n",
      "./out/valid/2007.csv\t13701377\t3G\n",
      "./out/valid/2008.csv\t13887804\t3G\n",
      "./out/valid/2009.csv\t13669082\t3G\n",
      "./out/valid/2010.csv\t13834281\t3G\n",
      "./out/valid/2011.csv\t13468614\t3G\n",
      "./out/valid/2012.csv\t14715369\t3G\n",
      "./out/valid/2013.csv\t15954359\t3G\n",
      "./out/valid/2014.csv\t15916904\t3G\n",
      "./out/valid/2015.csv\t15628917\t3G\n"
     ]
    }
   ],
   "source": [
    "# export\n",
    "if __name__ == '__main__':\n",
    "    print(*lsdir('./out/valid'), sep='\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
